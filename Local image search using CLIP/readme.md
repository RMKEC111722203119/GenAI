

# CLIP Image Search with Natural Language

This project demonstrates an image search application using OpenAI's CLIP (Contrastive Language-Image Pretraining) model. It allows users to search for images based on natural language queries.

## Features
Text-Based Image Search: Enter a descriptive text query to find images that match the description.
Image Gallery: Browse through a collection of preloaded images.
Similarity Scoring: Images are ranked by similarity to the text query using cosine similarity.

## Requirements
Python 3.6 or later
Streamlit
PyTorch
CLIP (pip install torch torchvision torchaudio clip)
